# ğŸ§© Feature Template: LLMChat Feature Definition

This template structures **Epic/Feature-level product ideas** into a clear, outcome-driven format â€” ready for story breakdown by engineering and design.

It is designed for **section-by-section collaboration between a PM and a GPT-based co-pilot**. The GPT acts as a thinking and writing partner â€” asking clarifying questions, suggesting better phrasing, and helping refine feature logic.

This document is intended to be iterated, not completed in one shot.

---

## 1. **User Story**

**Format:**  
_As a [user type], when I [trigger/context], I want to [action], so that [goal/value]._

**Purpose:**  
Capture the userâ€™s need, the context, and the value in one sentence.

âœ… Clarify if the task is vague, overly technical, or lacks a user type  
âœ… If appropriate, offer alternative phrasing  
ğŸ”¸ Ask: *What problem are they solving? Whatâ€™s the larger value?*

---

## 2. **Release Type**

What stage is this feature targeting?

- **POC** â€“ Internal-only proof of concept to validate feasibility  
- **Alpha** â€“ Limited-function release for internal feedback  
- **Beta** â€“ User-facing but not final; used to gather validation or early feedback  
- **GA** â€“ Full release to all users, production-ready

**Guidance:**  
âœ… Choose based on readiness and feedback goals  
âœ… It's common to pair Beta with a GA plan  
âœ… Include a short rationale for the stage chosen  

ğŸ”¸ Ask: *Is this intended for early validation or a full rollout?*  
ğŸ”¸ Ask: *Will users interact with this at this stage?*

---

## 3. **Business Requirements**

**WHAT this feature must achieve and WHY.**

âœ… Focus on outcomes, not UI or implementation  
âœ… Note IN vs. OUT of scope for this release  
âœ… End with the WHY: who benefits, and how

ğŸ’¡ Optional:  
> _Success = [measurable impact, workflow improvement, or outcome]_

ğŸ”¸ Ask: *What happens if we donâ€™t ship this?*  
ğŸ”¸ Ask: *What does success look like in practice?*

---

## 4. **Assumptions & Dependencies**

List any key assumptions or dependencies, such as:

- External systems or APIs  
- Design readiness  
- Technical gating conditions  
- Known risks or upstream blockers

âœ… Call out cross-team, integration, or architectural dependencies

ğŸ”¸ Ask: *What must be true for this to succeed?*  
ğŸ”¸ Ask: *What needs to be ready before this can begin?*  
ğŸ”¸ Ask: *What could delay or block this if proven false?*

---

## 5. **Foundational Research**

Choose one or more:
- No research needed  
- Discovery / Journey Mapping  
- Competitive UX Pattern Research  
- Technology / Architecture Scan

âœ… Research is often needed for novel UX, unknown user segments, or new domains  
ğŸ”¸ Ask: *Is this something weâ€™ve seen or done before?*

---

## 6. **UX Design Needs**

Select all that apply:
- No design needed  
- Low-fi wireframe (for exploration/ideation)  
- Mid-fi design (required for user-facing work)  
- High-fi design (for polish or clarity)  
- Interactive prototype (for testing or handoff)

**Guidance:**  
Donâ€™t assume design fidelity based on release stage.

- **Low-fi** is for internal exploration and early collaboration  
- **Mid- or High-fi** is expected for **any user-facing flows** (Alpha to GA)  
- **Prototypes** help test usability or clarify flows

âœ… Create design artifacts before implementation  
âœ… Choose the minimal artifact that supports confident development

ğŸ”¸ Ask: *What design input is needed to make decisions or move forward?*  
ğŸ”¸ Ask: *Does this impact UX enough to require visual exploration?*

---

## 7. **Logging Plan & Measuring Impact**

Split into:
- **Data to Capture** â€“ Key user/system actions, metadata, flags  
- **Metrics to Derive** â€“ What signals indicate success or failure?

**Guidance:**  
Use these lenses to guide metric thinking:

- **Usage** â€“ Are people finding/triggering the feature? (e.g., # activations, # users)  
- **Engagement** â€“ Are they using it meaningfully? (e.g., task completion, depth)  
- **Retention** â€“ Do they return or repeat usage?  
- **Abandonment** â€“ Are users dropping off, bouncing, or ignoring the feature?

âœ… Specify whatâ€™s logged today vs. what must be added  
âœ… Focus on signals of behavior, not vanity metrics  
âœ… Prioritize 1â€“2 metrics that match the featureâ€™s goals

ğŸ”¸ Ask: *What would tell us this feature is working?*  
ğŸ”¸ Ask: *What behavior would signal friction, confusion, or failure?*

---

## 8. **System Diagram Needs**

Choose one:
- Minor or no impact  
- System diagram update needed  
- Tech Wiki update needed

âœ… Update diagram if adding tools, APIs, or agents  
âœ… Update Tech Wiki if changing data flows or system behaviors

ğŸ”¸ Ask: *Would this change how a new dev understands the system?*

---

## 9. **Acceptance Criteria**

Break into 4 lists:
- **User Facing** â€” _As a user, I canâ€¦_  
- **Back End** â€” _The system shouldâ€¦_  
- **Logging** â€” _The product must captureâ€¦_  
- **Regression** â€” _The product should stillâ€¦_

âœ… Should be clear, testable, and aligned to the business need  
âœ… GPT can offer phrasing suggestions if PM input is unclear

ğŸ”¸ Ask: *Would you like help turning that into a testable statement?*  
ğŸ”¸ Ask: *What would QA or PM use to validate this?*

---

## 10. **Iteration Parking Lot (Unresolved Items)**

Use this section to note:
- Decisions still pending  
- Risky or unknown elements  
- Items deferred to a later release

âœ… Great for Alpha/Beta stages where discovery continues  
ğŸ”¸ Ask: *Whatâ€™s still fuzzy or in flux?*  
ğŸ”¸ Ask: *What do we expect to refine later?*

---

### âœ… Usage Tips

- This template is meant for **collaboration with a GPT co-pilot**. The GPT will prompt, clarify, and help refine each section â€” itâ€™s not a one-shot generator.  
- You donâ€™t have to finish everything in one pass. Write whatâ€™s clear, then iterate.  
- Always align with actual user value, not perceived completeness.

---

## ğŸ“˜ Appendix: Beta Types (Reference Only)

If selecting a **Beta** release, you may clarify the intent using one of these categories:

- **Usability Beta** â€“ Invite-only. Performed in test environments or structured sessions. Focus is on UX and workflow validation.  
- **Closed Beta** â€“ Invite-only on production. Used for early exposure and feedback from trusted users.  
- **Open Beta** â€“ Available to all users but clearly marked as pre-release. Used to gather large-scale feedback or monitor at-scale issues.

ğŸ“ Choose based on **feedback goals and risk**, not by default. These may evolve over time.
